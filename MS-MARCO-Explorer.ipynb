{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fdc7926-fb99-480c-8fe5-716080a883ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://msmarco.blob.core.windows.net/msmarco/train_v2.1.json.gz && mv train_v2.1.json.gz MSMARCO/\n",
    "# !wget https://msmarco.blob.core.windows.net/msmarco/dev_v2.1.json.gz && mv dev_v2.1.json.gz MSMARCO/\n",
    "# !wget https://msmarco.blob.core.windows.net/msmarco/eval_v2.1_public.json.gz && mv eval_v2.1_public.json.gz MSMARCO/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c51b70-4da7-49a8-8d81-919546004175",
   "metadata": {},
   "source": [
    "## Data Format (Estratto dal README originale: https://raw.githubusercontent.com/microsoft/MSMARCO-Question-Answering/master/README.md)\n",
    "Ogni entry contiene: query_id, query_type, query, passages, answers, and wellFormedAnswers.\n",
    "\n",
    "Per la task di Q&A l'output è presente nella chiave 'answers'. \n",
    "Per la task di NLG l'output è presente nella chiave 'wellFormedAnswers'.\n",
    "Delle 1,010,916 queries nel dataset Q&A, 182,669 hanno la risposta nella chiave 'wellFormedAnswers.\n",
    "\n",
    "1. query_id: identificatore univoco per ogni query\n",
    "2. query: una domanda espressa nel motore di ricerca Bing\n",
    "3. passages: un insieme di 10:passages, URLs, ed una flag per segnalare il loro utilizzo nella formulazione della risposta(is_selected:1). Due passages possono provenire dalla stessa URL, dal momento che sono stati ottenuti dai risultati di Bing in ordine di rilavanza. Se un passage è segnalato come is_selected:1 vuol dire che è stato utilizzato dal giudice per formare la risposta. Se al contrario è segnato come is_selected:0 indica che non è stato utilizzato per la formulazione della risposta. Domande la cui risposta è 'No Answer Present.' avranno is_selected: 0 in ognuno dei loro passaggi.\n",
    "4. query_type: una classificazione molto ad alto livello del tipo di domanda che è stata posta. La classificazione è fatta da un modello che punta alle segueni classi: {LOCATION,NUMERIC,PERSON,DESCRIPTION,ENTITY}. Può essere usato in fase di debug per investigare la distribuzione delle performance oppure per fare dei training più specifici.\n",
    "5. answers: un array di risposte prodotte dai giudici umani, la maggior parte contengono solo una risposta ma ~1% ne contiene di più(in media ~2 risposte dove la lista è più lunga di 1). Queste risposte sono state generate da pesone reali con parole loro, invece di selezionare uno span di testo. Il linguaggio usato nelle loro risposte può essere simile o uguale al linguaggio usato in qualsiasi dei passaggi.\n",
    "6. wellFormedAnswers. un array di risposte riscritte, come sopra di solito contiene una sola risposta, ma ~1% può contenerne più di una (in media ~5 risposte in caso di risposta multipla. Queste risposte sono generate da nuovi giudici, dopo aver letto la domanda e la risposta data precedentemente, verificandone (i) la grammatica, in modo da renderla una frase di senso compiuto, (ii) il senso in assenza di contesto o oppure in assenza di domanda, (iii) l'eccessivo overlap con porzioni di testo estratti direttametne dal paragrafo. Questo garantisce che la well formed answer sia verametne scritta in linguaggio naturale e non sia solo pura estrazione. Well Formed Answers sono più complesse per il Question answering dal momento che contengono parole che potrebbero non essere presenti in nessuno dei paragrafi o nel testo della domanda. \n",
    "\n",
    "example\n",
    "~~~\n",
    "{\n",
    "\t\"answers\":[\"A corporation is a company or group of people authorized to act as a single entity and recognized as such in law.\"],\n",
    "\t\"passages\":[\n",
    "\t\t{\n",
    "\t\t\t\"is_selected\":0,\n",
    "\t\t\t\"url\":\"http:\\/\\/www.wisegeek.com\\/what-is-a-corporation.htm\",\n",
    "\t\t\t\"passage_text\":\"A company is incorporated in a specific nation, often within the bounds of a smaller subset of that nation, such as a state or province. The corporation is then governed by the laws of incorporation in that state. A corporation may issue stock, either private or public, or may be classified as a non-stock corporation. If stock is issued, the corporation will usually be governed by its shareholders, either directly or indirectly.\"},\n",
    "\t\t...\n",
    "\t\t}],\n",
    "\t\"query\":\". what is a corporation?\",\n",
    "\t\"query_id\":1102432,\n",
    "\t\"query_type\":\"DESCRIPTION\",\n",
    "\t\"wellFormedAnswers\":\"[]\"\n",
    "}\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18ddb65f-ec52-4a85-b56c-23fe19ac6e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1d6ded5-3b1b-42ea-8329-7fb18abc79b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_marco = json.load(open(\"./MSMARCO/train_v2.1.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e9b9c38-25cc-4fd2-92c1-b47030d11d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_marco = json.load(open(\"./MSMARCO/dev_v2.1.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9d4d447-dd6b-40e4-a5b8-dd589cb74650",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 808731/808731 [00:03<00:00, 268239.46it/s]\n"
     ]
    }
   ],
   "source": [
    "tr_marco_collection = []\n",
    "for k in tqdm(tr_marco[\"query\"]):\n",
    "    question = tr_marco[\"query\"][k]\n",
    "    answers = tr_marco[\"answers\"][k]\n",
    "    wellFormedAnswers = tr_marco[\"wellFormedAnswers\"][k]\n",
    "    context = \"\"\n",
    "    for passage in tr_marco[\"passages\"][k]:\n",
    "        if passage[\"is_selected\"] == 1:\n",
    "            context += passage[\"passage_text\"]+\"\\n\"\n",
    "   \n",
    "    tr_marco_collection.append({\n",
    "        \"question\": question,\n",
    "        \"answers\": answers,\n",
    "        \"wellFormedAnswers\": wellFormedAnswers,\n",
    "        \"context\": context\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f1de690-f78b-4345-9c52-a2ee1556af52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101093/101093 [00:00<00:00, 417932.19it/s]\n"
     ]
    }
   ],
   "source": [
    "dev_marco_collection = []\n",
    "for k in tqdm(dev_marco[\"query\"]):\n",
    "    question = dev_marco[\"query\"][k]\n",
    "    answers = dev_marco[\"answers\"][k]\n",
    "    wellFormedAnswers = dev_marco[\"wellFormedAnswers\"][k]\n",
    "    context = \"\"\n",
    "    for passage in dev_marco[\"passages\"][k]:\n",
    "        if passage[\"is_selected\"] == 1:\n",
    "            context += passage[\"passage_text\"]+\"\\n\"\n",
    "            \n",
    "    dev_marco_collection.append({\n",
    "        \"question\": question,\n",
    "        \"answers\": answers,\n",
    "        \"wellFormedAnswers\": wellFormedAnswers,\n",
    "        \"context\": context\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "903aa2f3-e39a-4fc8-a514-bd53e30e4217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Training Example from Collection *****\n",
      "{'answers': ['The immediate impact of the success of the manhattan project was '\n",
      "             'the only cloud hanging over the impressive achievement of the '\n",
      "             'atomic researchers and engineers is what their success truly '\n",
      "             'meant; hundreds of thousands of innocent lives obliterated.'],\n",
      " 'context': 'The presence of communication amid scientific minds was equally '\n",
      "            'important to the success of the Manhattan Project as scientific '\n",
      "            'intellect was. The only cloud hanging over the impressive '\n",
      "            'achievement of the atomic researchers and engineers is what their '\n",
      "            'success truly meant; hundreds of thousands of innocent lives '\n",
      "            'obliterated.\\n',\n",
      " 'question': ')what was the immediate impact of the success of the manhattan '\n",
      "             'project?',\n",
      " 'wellFormedAnswers': '[]'}\n",
      "\n",
      "\n",
      "\n",
      "***** Dev Example from Collection *****\n",
      "{'answers': ['A corporation is a company or group of people authorized to act '\n",
      "             'as a single entity and recognized as such in law.'],\n",
      " 'context': \"McDonald's Corporation is one of the most recognizable \"\n",
      "            'corporations in the world. A corporation is a company or group of '\n",
      "            'people authorized to act as a single entity (legally a person) '\n",
      "            'and recognized as such in law. Early incorporated entities were '\n",
      "            'established by charter (i.e. by an ad hoc act granted by a '\n",
      "            'monarch or passed by a parliament or legislature).\\n',\n",
      " 'question': '. what is a corporation?',\n",
      " 'wellFormedAnswers': '[]'}\n"
     ]
    }
   ],
   "source": [
    "print(\"***** Training Example from Collection *****\")\n",
    "pprint.pprint(tr_marco_collection[0])\n",
    "print(\"\\n\\n\")\n",
    "print(\"***** Dev Example from Collection *****\")\n",
    "pprint.pprint(dev_marco_collection[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d230b6b2-a44f-4b20-931c-4b04452edede",
   "metadata": {},
   "source": [
    "## Natural Language Generation\n",
    "\n",
    "Come facciamo ad usare le informazioni all'interno di Marco per creare un Q&A generativo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ba6de9-f3ef-4848-b3ec-5f1fa4f620cf",
   "metadata": {},
   "source": [
    "### 1. Approaccio - HuggingFace pretrained \n",
    "\n",
    "Cerchiamo su huggingface un modello in grado di generare Conditioned Text, e lo testiamo sul Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65d9dfde-9756-4e34-9881-bc4957e6b48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "from rouge import Rouge \n",
    "import numpy as np\n",
    "\n",
    "rouge = Rouge()\n",
    "# https://www.aclweb.org/anthology/W04-1013/\n",
    "# https://towardsdatascience.com/evaluating-text-output-in-nlp-bleu-at-your-own-risk-e8609665a213"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96e6e933-0c28-4258-8ffe-87e9b599f2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"valhalla/t5-base-qa-qg-hl\")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"valhalla/t5-base-qa-qg-hl\")\n",
    "\n",
    "nlp = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63af1b87-886a-44c0-b71b-46d1751a8ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'What is the answer to life, the universe and everything?'}]\n",
      "[{'generated_text': 'the answer to life, the universe and everything'}]\n"
     ]
    }
   ],
   "source": [
    "# to generate questions simply pass the text\n",
    "answer = nlp(\"42 is the answer to life, the universe and everything.\")\n",
    "print(answer)\n",
    "#=> [{'answer': '42', 'question': 'What is the answer to life, the universe and everything?'}]\n",
    "\n",
    "# for qa pass a dict with \"question\" and \"context\"\n",
    "answer = nlp(\"question: What is 42 ? context: 42 is the answer to life, the universe and everything.\")\n",
    "print(answer)\n",
    "#=> 'the answer to life, the universe and everything'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "751a2fc4-fa2c-4146-9676-f6ffff22601d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4087/101093 [00:00<00:00, 1151792.01it/s]\n",
      "100%|██████████| 1000/1000 [07:11<00:00,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV Set Answer Rouge-L F-score: 0.3131871215774918\n",
      "DEV Set Well Formed Answer Rouge-L F-score: 0.34997590167395515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "answers_rouge = []\n",
    "wellformedanswers_rouge = []\n",
    "exceptions_occurred = []\n",
    "# Selezioniamo 500 answer senza WellFormed version, e 500 WellFormed version\n",
    "np.random.shuffle(dev_marco_collection)\n",
    "\n",
    "dev_marco_collection_subset = []\n",
    "n_answers = 0\n",
    "n_wellformed = 0\n",
    "for dev_sample in tqdm(dev_marco_collection):\n",
    "    if dev_sample[\"wellFormedAnswers\"] != '[]' and n_wellformed < 500:\n",
    "        n_wellformed += 1\n",
    "        dev_marco_collection_subset.append(dev_sample)\n",
    "    elif n_answers < 500:\n",
    "        n_answers += 1\n",
    "        dev_marco_collection_subset.append(dev_sample)\n",
    "    elif n_answers >= 500 and n_wellformed >= 500:\n",
    "        break\n",
    "\n",
    "np.random.shuffle(dev_marco_collection_subset)\n",
    "\n",
    "for i,dev_sample in enumerate(tqdm(dev_marco_collection_subset)):\n",
    "    question = dev_sample[\"question\"]\n",
    "    context = dev_sample[\"context\"]\n",
    "    predicted_answer = nlp(\"question: \"+question+\" context: \"+context)[0][\"generated_text\"]\n",
    "\n",
    "    answers_int_rouge = []\n",
    "    for real_answer in dev_sample[\"answers\"]:\n",
    "        try:\n",
    "            answers_int_rouge.append(rouge.get_scores(predicted_answer, real_answer)[0][\"rouge-l\"][\"f\"])\n",
    "        except Exception as e:\n",
    "                exceptions_occurred.append(str(e))\n",
    "            answers_int_rouge.append(0)\n",
    "    \n",
    "    if not answers_int_rouge:\n",
    "        answers_int_rouge = [0]\n",
    "    \n",
    "    answers_rouge.append( np.mean(answers_int_rouge) )\n",
    "    \n",
    "    if dev_sample[\"wellFormedAnswers\"] != '[]':\n",
    "        wellformedanswers_int_rouge = []\n",
    "        for real_wellformedanswer in dev_sample[\"wellFormedAnswers\"]:\n",
    "            try:\n",
    "                wellformedanswers_int_rouge.append(rouge.get_scores(predicted_answer, real_wellformedanswer)[0][\"rouge-l\"][\"f\"])\n",
    "            except Exception as e:\n",
    "                exceptions_occurred.append(str(e))\n",
    "                wellformedanswers_int_rouge.append(0)\n",
    "                \n",
    "        if not wellformedanswers_int_rouge:\n",
    "            wellformedanswers_int_rouge = [0]\n",
    "\n",
    "        wellformedanswers_rouge.append( np.mean(wellformedanswers_int_rouge) )\n",
    "        \n",
    "        dev_marco_collection_subset[i][\"wellformed_score\"] = np.mean(wellformedanswers_int_rouge) \n",
    "    else:\n",
    "        dev_marco_collection_subset[i][\"wellformed_score\"] = 0.0\n",
    "        \n",
    "    dev_marco_collection_subset[i][\"predicted_answer\"] = predicted_answer\n",
    "    dev_marco_collection_subset[i][\"score\"] = np.mean(answers_int_rouge)\n",
    "\n",
    "print(f\"DEV Set Answer Rouge-L F-score: {np.mean(answers_rouge)}\")\n",
    "print(f\"DEV Set Well Formed Answer Rouge-L F-score: {np.mean(wellformedanswers_rouge)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f782cb20-fca5-4020-8447-a43fcf9dc08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors during tests: ['Hypothesis is empty.']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Errors during tests: {np.unique(exceptions_occurred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8417cafc-0e24-4c91-b593-d9d74098d87f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ****** \n",
      "QUESTION: who is advanced management group\n",
      "ANSWER: ['No Answer Present.']\n",
      "WELL FORMED ANSWER: []\n",
      "PREDICTED ANSWER: .\n",
      "WELLFORMED SCORE: 0.0\n",
      "NORMAL ANSWER SCORE: 0.0\n",
      " ****** \n",
      "QUESTION: eating more of what will prevent heart disease\n",
      "ANSWER: ['Eating avocado, along with avocado oil or even peel, salmon, trout, or herring, or from flaxseed, kale, spinach, or walnuts will prevent heart disease.']\n",
      "WELL FORMED ANSWER: []\n",
      "PREDICTED ANSWER: healthy fats\n",
      "WELLFORMED SCORE: 0.0\n",
      "NORMAL ANSWER SCORE: 0.0\n",
      " ****** \n",
      "QUESTION: Steven Sanders poem, you are men who in your lives fought for\n",
      "ANSWER: ['No Answer Present.']\n",
      "WELL FORMED ANSWER: []\n",
      "PREDICTED ANSWER: fought for context\n",
      "WELLFORMED SCORE: 0.0\n",
      "NORMAL ANSWER SCORE: 0.0\n",
      " ****** \n",
      "QUESTION: when is the baltimore orioles home opener\n",
      "ANSWER: ['The Baltimore Orioles home opener at Oriole Park at Camden Yards was on April 10, 2015 in Baltimore, Maryland.']\n",
      "WELL FORMED ANSWER: []\n",
      "PREDICTED ANSWER: April 10, 2015\n",
      "WELLFORMED SCORE: 0.0\n",
      "NORMAL ANSWER SCORE: 0.2857142832653061\n",
      " ****** \n",
      "QUESTION: who were the commanders of the battle of gettysburg\n",
      "ANSWER: ['General Robert E. Lee was the commanders of the battle of Gettysburg.']\n",
      "WELL FORMED ANSWER: []\n",
      "PREDICTED ANSWER: Confederate commanders\n",
      "WELLFORMED SCORE: 0.0\n",
      "NORMAL ANSWER SCORE: 0.16666666388888893\n",
      " ****** \n",
      "QUESTION: what are monomer\n",
      "ANSWER: ['Monomers are small molecules which may be joined together in a repeating fashion to form more complex molecules called polymers.']\n",
      "WELL FORMED ANSWER: ['Monomers are small molecules which may be joined together in a repeating fashion to form more complex molecules called polymers.']\n",
      "PREDICTED ANSWER: Monomers are small molecules which may be joined together in a repeating fashion to form more\n",
      "WELLFORMED SCORE: 0.914285709322449\n",
      "NORMAL ANSWER SCORE: 0.914285709322449\n",
      " ****** \n",
      "QUESTION: where is the source of the amazon river\n",
      "ANSWER: ['The geographic source of the Amazon River in Mt. Nevado Mismi of Peru.']\n",
      "WELL FORMED ANSWER: ['The geographic source of the Amazon River is in of Peru.', 'The geographic source of the Amazon River is in Mountain Nevado Mismi of Peru.']\n",
      "PREDICTED ANSWER: Mt. Nevado Mismi of Peru\n",
      "WELLFORMED SCORE: 0.35555555132716055\n",
      "NORMAL ANSWER SCORE: 0.588235289965398\n",
      " ****** \n",
      "QUESTION: explain how cells know whether or not to divide\n",
      "ANSWER: ['Once it has copied all its DNA, a cell normally divides into two new cells.']\n",
      "WELL FORMED ANSWER: ['Once it has copied all its DNA, a cell normally divides into two new cells.']\n",
      "PREDICTED ANSWER: mitosis\n",
      "WELLFORMED SCORE: 0.0\n",
      "NORMAL ANSWER SCORE: 0.0\n",
      " ****** \n",
      "QUESTION: can hives be a sign of pregnancy\n",
      "ANSWER: ['Yes, hives can be a sign of pregnancy.']\n",
      "WELL FORMED ANSWER: []\n",
      "PREDICTED ANSWER: can be caused by an allergic reaction to almost anything\n",
      "WELLFORMED SCORE: 0.0\n",
      "NORMAL ANSWER SCORE: 0.22222221728395072\n",
      " ****** \n",
      "QUESTION: what flowers are in season in august\n",
      "ANSWER: ['No Answer Present.']\n",
      "WELL FORMED ANSWER: []\n",
      "PREDICTED ANSWER: .\n",
      "WELLFORMED SCORE: 0.0\n",
      "NORMAL ANSWER SCORE: 0.0\n",
      " ****** \n",
      "QUESTION: average price per square foot for concrete flat work\n",
      "ANSWER: ['The average cost of a concrete slab will be between $5 and $7 dollars per square foot or $135 and $189 per cubic yard.']\n",
      "WELL FORMED ANSWER: ['The average cost of a concrete slab will be between $5 and $7 dollars per square foot or $135 and $189 per cubic yard.', 'The average cost of a concrete slab will be between $5 and $7 dollars per square foot.']\n",
      "PREDICTED ANSWER: between $5 and $7 dollars per square foot or $135 and $189 per cubic yard\n",
      "WELLFORMED SCORE: 0.6380952333049887\n",
      "NORMAL ANSWER SCORE: 0.7428571381877552\n",
      " ****** \n",
      "QUESTION: what is oregano oil used to treat\n",
      "ANSWER: ['Skin conditions like cold sores, muscle aches, nail fungus, joint pain, and dandruff.']\n",
      "WELL FORMED ANSWER: ['Oregano oil is used to treat skin conditions like cold sores, muscle aches, nail fungus, joint pain, and dandruff.']\n",
      "PREDICTED ANSWER: cold sores, muscle aches, nail fungus, joint pain, and \n",
      "WELLFORMED SCORE: 0.642857138494898\n",
      "NORMAL ANSWER SCORE: 0.8181818133471075\n",
      " ****** \n",
      "QUESTION: how many deaths in united states a year\n",
      "ANSWER: ['No Answer Present.']\n",
      "WELL FORMED ANSWER: []\n",
      "PREDICTED ANSWER: a year\n",
      "WELLFORMED SCORE: 0.0\n",
      "NORMAL ANSWER SCORE: 0.0\n",
      " ****** \n",
      "QUESTION: what are lab information systems\n",
      "ANSWER: [\"A software-based laboratory and information management system with features that support a modern laboratory's operations.\"]\n",
      "WELL FORMED ANSWER: [\"A Lab Information System is a software based laboratory and information management system with features that support a modern laboratory's operations.\", \"Lab information systems is a software-based laboratory and information management system with features that support a modern laboratory's operations.\"]\n",
      "PREDICTED ANSWER: a software-based laboratory and information management system with features that support a modern laboratory'\n",
      "WELLFORMED SCORE: 0.7333333284902664\n",
      "NORMAL ANSWER SCORE: 0.8571428521683674\n",
      " ****** \n",
      "QUESTION: how do powerlifting singlets work\n",
      "ANSWER: ['No Answer Present.']\n",
      "WELL FORMED ANSWER: []\n",
      "PREDICTED ANSWER: powerlifting\n",
      "WELLFORMED SCORE: 0.0\n",
      "NORMAL ANSWER SCORE: 0.0\n",
      " ****** \n",
      "QUESTION: how the george washington bridge was built\n",
      "ANSWER: ['Architect Cass Gilbert intended its towers to be sheathed in stone. Still visible on the towers are the hooks for which the stone was to be attached. Proposed Original Design With Stone Arches.']\n",
      "WELL FORMED ANSWER: []\n",
      "PREDICTED ANSWER: Architect Cass Gilbert intended its towers to be sheathed in stone\n",
      "WELLFORMED SCORE: 0.0\n",
      "NORMAL ANSWER SCORE: 0.5789473643074793\n",
      " ****** \n",
      "QUESTION: how does the constitution provide justice\n",
      "ANSWER: ['The Constitution of the United States of America is the supreme law of the United States. Empowered with the sovereign authority of the people by the framers and the consent of the legislatures of the states, it is the source of all government powers, and also provides important limitations on the government that protect the fundamental rights of United States citizens.']\n",
      "WELL FORMED ANSWER: ['The constitution provides justice because it is the supreme law of the United States empowered with the sovereign authority of the people by the framers and the consent of the legislatures of the states, it is the source of all government powers, and also provides important limitations on the government that protect the fundamental rights of United States citizens.', 'The Constitution of the United States of America is the supreme law of the United States. Empowered with the sovereign authority of the people by the framers and the consent of the legislatures of the states, it is the source of all government powers, and also provides important limitations on the government that protect the fundamental rights of United States citizens.']\n",
      "PREDICTED ANSWER: Empowered with the sovereign authority of the people by the framers and the consent of the\n",
      "WELLFORMED SCORE: 0.4423758829656633\n",
      "NORMAL ANSWER SCORE: 0.4680851027976461\n",
      " ****** \n",
      "QUESTION: what does csp stand for? in construction\n",
      "ANSWER: ['CSP stands for Contract Service Providers.']\n",
      "WELL FORMED ANSWER: ['In construction, CSP stands for Contract Service Providers.', 'CSP stands for Contract Service Providers.']\n",
      "PREDICTED ANSWER: Contract Service Providers\n",
      "WELLFORMED SCORE: 0.6060606018549128\n",
      "NORMAL ANSWER SCORE: 0.6666666622222223\n",
      " ****** \n",
      "QUESTION: what costs did hurst want from leeming\n",
      "ANSWER: ['No Answer Present.']\n",
      "WELL FORMED ANSWER: []\n",
      "PREDICTED ANSWER: hurst wanted from leeming\n",
      "WELLFORMED SCORE: 0.0\n",
      "NORMAL ANSWER SCORE: 0.0\n",
      " ****** \n",
      "QUESTION: what county is highlands ranch\n",
      "ANSWER: ['Douglas']\n",
      "WELL FORMED ANSWER: ['Highlands Ranch is in Douglas County.']\n",
      "PREDICTED ANSWER: Douglas County\n",
      "WELLFORMED SCORE: 0.4999999962500001\n",
      "NORMAL ANSWER SCORE: 0.6666666622222223\n"
     ]
    }
   ],
   "source": [
    "for i,dev_sample in enumerate(dev_marco_collection_subset):\n",
    "    if i >= 20:\n",
    "        break\n",
    "    print(\" ****** \")\n",
    "    print(f\"QUESTION: {dev_sample['question']}\")\n",
    "    print(f\"ANSWER: {dev_sample['answers']}\")\n",
    "    print(f\"WELL FORMED ANSWER: {dev_sample['wellFormedAnswers']}\")\n",
    "    print(f\"PREDICTED ANSWER: {dev_sample['predicted_answer']}\")\n",
    "    print(f\"WELLFORMED SCORE: {dev_sample['wellformed_score']}\")\n",
    "    print(f\"NORMAL ANSWER SCORE: {dev_sample['score']}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4a4a6f-94e7-450b-818a-1ab82d3769b0",
   "metadata": {},
   "source": [
    "### Fine tuning del modello\n",
    "\n",
    "Per migliorare le performance è possibile utilizzare diverse tecniche:\n",
    "1. HuggingFace training: https://huggingface.co/transformers/training.html\n",
    "2. Il repository di questo modello seguendo il readme: https://github.com/patil-suraj/question_generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6cbfa8-886c-4d51-9274-af156d36fc0f",
   "metadata": {},
   "source": [
    "### 2. Approccio - Parafrasi\n",
    "\n",
    "Il concetto è molto semplice: vogliamo parafrasare l'input e la risposta trovata in modo da poter essere sicuri che qualsiasi cosa che venga estratto non sia scritta come nel testo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d640435b-b00e-4075-9da0-4f5db715ae6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "model_name = 'tuner007/pegasus_paraphrase'\n",
    "torch_device = 'cpu'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
    "\n",
    "def get_response(input_text,num_return_sequences,num_beams):\n",
    "    batch = tokenizer([input_text],truncation=True,padding='longest',max_length=60, return_tensors=\"pt\").to(torch_device)\n",
    "    translated = model.generate(**batch,max_length=60,num_beams=num_beams, num_return_sequences=num_return_sequences, temperature=1.5)\n",
    "    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    return tgt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c25bfc01-cab6-479f-920d-1e343b444a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/calogero/miniconda3/envs/qa-huggingface/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Which data science course should I take?',\n",
       " 'Which data science course should I take first?',\n",
       " 'Should I take a data science course?',\n",
       " 'Which data science class should I take?',\n",
       " 'Which data science course should I attend?',\n",
       " 'I want to get started in data science.',\n",
       " 'Which data science course should I enroll in?',\n",
       " 'Which data science course is right for me?',\n",
       " 'Which data science course is best for me?',\n",
       " 'Which course should I take to get started?']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_beams = 10\n",
    "num_return_sequences = 10\n",
    "#context = \"The ultimate test of your knowledge is your capacity to convey it to another.\"\n",
    "context = \"Which course should I take to get started in data science?\"\n",
    "get_response(context,num_return_sequences,num_beams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d1795c4-0ce3-40a6-bee4-76d8b78afd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device  cpu\n",
      "\n",
      "Original Question ::\n",
      "The ultimate test of your knowledge is your capacity to convey it to another.\n",
      "\n",
      "\n",
      "Paraphrased Questions :: \n",
      "0: The ultimate test of knowledge is your ability to convey it to another person.\n",
      "1: What is the ultimate test of one's knowledge? How can one communicate this knowledge to another?\n",
      "2: The ultimate test of knowledge is your capacity to convey it to another.\n",
      "3: What's the test of knowledge is your capacity to communicate to others with accuracy?\n",
      "4: COURSE: The ultimate test of knowledge is your capacity to convey it to someone.\n",
      "5: What is the test of knowledge?\n",
      "6: How well you can convey information about yourself?\n",
      "7: The ultimate test for your knowledge is your ability to share it with another.\n",
      "8: If we are learning a new language, the test for what we know is our capacity to communicate it to others..everyone can gain it.\n",
      "9: What is the test of your ability to convey information that is unknown to you?\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('ramsrigouthamg/t5_paraphraser')\n",
    "tokenizer = T5Tokenizer.from_pretrained('ramsrigouthamg/t5_paraphraser')\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "print (\"device \",device)\n",
    "model = model.to(device)\n",
    "\n",
    "#sentence = \"Which course should I take to get started in data science?\"\n",
    "sentence = \"The ultimate test of your knowledge is your capacity to convey it to another.\"\n",
    "# sentence = \"What are the ingredients required to bake a perfect cake?\"\n",
    "# sentence = \"What is the best possible approach to learn aeronautical engineering?\"\n",
    "# sentence = \"Do apples taste better than oranges in general?\"\n",
    "\n",
    "\n",
    "text =  \"paraphrase: \" + sentence + \" </s>\"\n",
    "\n",
    "\n",
    "max_len = 256\n",
    "\n",
    "encoding = tokenizer.encode_plus(text,pad_to_max_length=True, return_tensors=\"pt\")\n",
    "input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "\n",
    "# set top_k = 50 and set top_p = 0.95 and num_return_sequences = 3\n",
    "beam_outputs = model.generate(\n",
    "    input_ids=input_ids, attention_mask=attention_masks,\n",
    "    do_sample=True,\n",
    "    max_length=256,\n",
    "    top_k=120,\n",
    "    top_p=0.98,\n",
    "    early_stopping=True,\n",
    "    num_return_sequences=10\n",
    ")\n",
    "\n",
    "\n",
    "print (\"\\nOriginal Question ::\")\n",
    "print (sentence)\n",
    "print (\"\\n\")\n",
    "print (\"Paraphrased Questions :: \")\n",
    "final_outputs =[]\n",
    "for beam_output in beam_outputs:\n",
    "    sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
    "    if sent.lower() != sentence.lower() and sent not in final_outputs:\n",
    "        final_outputs.append(sent)\n",
    "\n",
    "for i, final_output in enumerate(final_outputs):\n",
    "    print(\"{}: {}\".format(i, final_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed64159e-7ce4-454d-81d4-25cbbbc6d157",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
